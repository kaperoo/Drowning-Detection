[I 2023-04-20 11:39:18,277] Trial 0 finished with value: 11.448763250883392 and parameters: {'learning_rate': 0.0030112549930871053, 'batch_size': 4, 'num_epochs': 31, 'conv1_channels': 142, 'conv2_channels': 73, 'conv3_channels': 78, 'hidden_channels': 101, 'hidden_layers': 4}. Best is trial 0 with value: 11.448763250883392.
[I 2023-04-20 12:11:39,647] Trial 1 finished with value: 25.547703180212014 and parameters: {'learning_rate': 0.0001623490006340104, 'batch_size': 4, 'num_epochs': 58, 'conv1_channels': 165, 'conv2_channels': 252, 'conv3_channels': 75, 'hidden_channels': 90, 'hidden_layers': 3}. Best is trial 1 with value: 25.547703180212014.
[I 2023-04-20 12:35:01,694] Trial 2 finished with value: 11.87279151943463 and parameters: {'learning_rate': 0.0520255176802831, 'batch_size': 4, 'num_epochs': 39, 'conv1_channels': 177, 'conv2_channels': 170, 'conv3_channels': 208, 'hidden_channels': 100, 'hidden_layers': 2}. Best is trial 1 with value: 25.547703180212014.
[I 2023-04-20 12:41:11,349] Trial 3 finished with value: 9.858657243816255 and parameters: {'learning_rate': 0.03231204790630471, 'batch_size': 16, 'num_epochs': 41, 'conv1_channels': 87, 'conv2_channels': 119, 'conv3_channels': 245, 'hidden_channels': 78, 'hidden_layers': 2}. Best is trial 1 with value: 25.547703180212014.
[I 2023-04-20 12:54:08,934] Trial 4 finished with value: 13.03886925795053 and parameters: {'learning_rate': 0.0017579561153627408, 'batch_size': 8, 'num_epochs': 58, 'conv1_channels': 165, 'conv2_channels': 64, 'conv3_channels': 92, 'hidden_channels': 75, 'hidden_layers': 4}. Best is trial 1 with value: 25.547703180212014.
[I 2023-04-20 12:54:23,012] Trial 5 pruned.
[I 2023-04-20 12:54:53,858] Trial 6 pruned.
[I 2023-04-20 13:12:18,569] Trial 7 pruned.
[I 2023-04-20 13:12:29,788] Trial 8 pruned.
[I 2023-04-20 13:19:26,753] Trial 9 finished with value: 26.819787985865723 and parameters: {'learning_rate': 9.586378083860256e-05, 'batch_size': 16, 'num_epochs': 39, 'conv1_channels': 186, 'conv2_channels': 188, 'conv3_channels': 95, 'hidden_channels': 109, 'hidden_layers': 2}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 13:25:30,149] Trial 10 finished with value: 23.74558303886926 and parameters: {'learning_rate': 1.0040402149790569e-05, 'batch_size': 16, 'num_epochs': 24, 'conv1_channels': 238, 'conv2_channels': 216, 'conv3_channels': 185, 'hidden_channels': 123, 'hidden_layers': 3}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 13:35:43,183] Trial 11 finished with value: 25.97173144876325 and parameters: {'learning_rate': 0.0001304672476737476, 'batch_size': 16, 'num_epochs': 49, 'conv1_channels': 211, 'conv2_channels': 256, 'conv3_channels': 111, 'hidden_channels': 50, 'hidden_layers': 3}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 13:44:21,453] Trial 12 finished with value: 26.713780918727917 and parameters: {'learning_rate': 0.00017549812638927964, 'batch_size': 16, 'num_epochs': 49, 'conv1_channels': 212, 'conv2_channels': 148, 'conv3_channels': 116, 'hidden_channels': 50, 'hidden_layers': 3}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 13:44:33,929] Trial 13 pruned.
[I 2023-04-20 13:49:14,411] Trial 14 finished with value: 25.12367491166078 and parameters: {'learning_rate': 3.893737740169632e-05, 'batch_size': 16, 'num_epochs': 32, 'conv1_channels': 102, 'conv2_channels': 162, 'conv3_channels': 108, 'hidden_channels': 51, 'hidden_layers': 3}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 13:49:26,707] Trial 15 pruned.
[I 2023-04-20 13:53:30,703] Trial 16 finished with value: 25.229681978798588 and parameters: {'learning_rate': 5.402696051200167e-05, 'batch_size': 16, 'num_epochs': 21, 'conv1_channels': 256, 'conv2_channels': 135, 'conv3_channels': 120, 'hidden_channels': 128, 'hidden_layers': 4}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 13:53:48,013] Trial 17 pruned.
[I 2023-04-20 13:53:55,618] Trial 18 pruned.
[I 2023-04-20 13:54:05,320] Trial 19 pruned.
[I 2023-04-20 14:08:16,280] Trial 20 finished with value: 26.289752650176677 and parameters: {'learning_rate': 2.6081773199502837e-05, 'batch_size': 8, 'num_epochs': 53, 'conv1_channels': 226, 'conv2_channels': 114, 'conv3_channels': 207, 'hidden_channels': 85, 'hidden_layers': 3}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 14:08:33,088] Trial 21 pruned.
[I 2023-04-20 14:08:41,421] Trial 22 pruned.
[I 2023-04-20 14:15:25,971] Trial 23 finished with value: 26.607773851590107 and parameters: {'learning_rate': 2.3650622272227133e-05, 'batch_size': 8, 'num_epochs': 45, 'conv1_channels': 193, 'conv2_channels': 161, 'conv3_channels': 144, 'hidden_channels': 113, 'hidden_layers': 4}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 14:15:34,985] Trial 24 pruned.
[I 2023-04-20 14:16:07,478] Trial 25 pruned.
[I 2023-04-20 14:23:15,986] Trial 26 finished with value: 26.713780918727917 and parameters: {'learning_rate': 6.190717084749886e-05, 'batch_size': 8, 'num_epochs': 48, 'conv1_channels': 175, 'conv2_channels': 213, 'conv3_channels': 101, 'hidden_channels': 106, 'hidden_layers': 4}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 14:27:44,707] Trial 27 finished with value: 24.593639575971732 and parameters: {'learning_rate': 7.826227301146792e-05, 'batch_size': 16, 'num_epochs': 49, 'conv1_channels': 168, 'conv2_channels': 225, 'conv3_channels': 95, 'hidden_channels': 105, 'hidden_layers': 4}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 14:27:53,048] Trial 28 pruned.
[I 2023-04-20 14:29:14,031] Trial 29 pruned.
[I 2023-04-20 14:29:29,440] Trial 30 pruned.
[I 2023-04-20 14:31:02,572] Trial 31 pruned.
[I 2023-04-20 14:36:56,181] Trial 32 finished with value: 26.289752650176677 and parameters: {'learning_rate': 0.00012928314278995556, 'batch_size': 8, 'num_epochs': 41, 'conv1_channels': 157, 'conv2_channels': 179, 'conv3_channels': 67, 'hidden_channels': 124, 'hidden_layers': 4}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 14:37:04,788] Trial 33 pruned.
[I 2023-04-20 14:45:15,548] Trial 34 finished with value: 26.819787985865723 and parameters: {'learning_rate': 4.9322355035044935e-05, 'batch_size': 8, 'num_epochs': 54, 'conv1_channels': 173, 'conv2_channels': 209, 'conv3_channels': 87, 'hidden_channels': 108, 'hidden_layers': 4}. Best is trial 9 with value: 26.819787985865723.
[I 2023-04-20 14:45:47,345] Trial 35 pruned.
[I 2023-04-20 14:45:55,429] Trial 36 pruned.
[I 2023-04-20 14:46:04,202] Trial 37 pruned.
[I 2023-04-20 14:46:33,777] Trial 38 pruned.
[I 2023-04-20 14:46:38,555] Trial 39 pruned.
[I 2023-04-20 14:47:30,519] Trial 40 pruned.
[I 2023-04-20 14:47:39,017] Trial 41 pruned.
[I 2023-04-20 14:49:13,208] Trial 42 pruned.
[I 2023-04-20 14:49:22,594] Trial 43 pruned.
[I 2023-04-20 14:49:31,292] Trial 44 pruned.
[I 2023-04-20 14:49:41,940] Trial 45 pruned.
[I 2023-04-20 14:49:56,302] Trial 46 pruned.
[I 2023-04-20 14:50:17,202] Trial 47 pruned.
[I 2023-04-20 14:53:09,309] Trial 48 pruned.
[I 2023-04-20 14:53:15,104] Trial 49 pruned.
[I 2023-04-20 14:53:47,304] Trial 50 pruned.
[I 2023-04-20 14:55:20,903] Trial 51 pruned.
[I 2023-04-20 14:56:10,870] Trial 52 pruned.
[I 2023-04-20 14:56:29,593] Trial 53 pruned.
[I 2023-04-20 14:57:02,518] Trial 54 pruned.
[I 2023-04-20 14:57:23,504] Trial 55 pruned.
[I 2023-04-20 14:58:47,633] Trial 56 pruned.
[I 2023-04-20 14:59:03,941] Trial 57 pruned.
[I 2023-04-20 14:59:36,694] Trial 58 pruned.
[I 2023-04-20 15:00:38,392] Trial 59 pruned.
[I 2023-04-20 15:00:53,300] Trial 60 pruned.
[I 2023-04-20 15:01:27,620] Trial 61 pruned.
[I 2023-04-20 15:01:36,472] Trial 62 pruned.
[I 2023-04-20 15:07:02,624] Trial 63 finished with value: 26.925795053003533 and parameters: {'learning_rate': 9.143381850322516e-05, 'batch_size': 8, 'num_epochs': 37, 'conv1_channels': 187, 'conv2_channels': 176, 'conv3_channels': 66, 'hidden_channels': 114, 'hidden_layers': 4}. Best is trial 63 with value: 26.925795053003533.
[I 2023-04-20 15:07:11,201] Trial 64 pruned.
[I 2023-04-20 15:07:20,455] Trial 65 pruned.
[I 2023-04-20 15:14:38,477] Trial 66 finished with value: 25.01766784452297 and parameters: {'learning_rate': 6.395250825430639e-05, 'batch_size': 8, 'num_epochs': 48, 'conv1_channels': 184, 'conv2_channels': 248, 'conv3_channels': 51, 'hidden_channels': 114, 'hidden_layers': 4}. Best is trial 63 with value: 26.925795053003533.
[I 2023-04-20 15:14:44,466] Trial 67 pruned.
[I 2023-04-20 15:14:54,245] Trial 68 pruned.
[I 2023-04-20 15:14:59,659] Trial 69 pruned.
[I 2023-04-20 15:15:07,814] Trial 70 pruned.
[I 2023-04-20 15:15:24,261] Trial 71 pruned.
[I 2023-04-20 15:15:59,282] Trial 72 pruned.
[I 2023-04-20 15:16:17,147] Trial 73 pruned.
[I 2023-04-20 15:16:25,734] Trial 74 pruned.
[I 2023-04-20 15:16:34,401] Trial 75 pruned.
[I 2023-04-20 15:19:26,527] Trial 76 pruned.
[I 2023-04-20 15:19:45,930] Trial 77 pruned.
[I 2023-04-20 15:19:55,725] Trial 78 pruned.
[I 2023-04-20 15:20:05,411] Trial 79 pruned.
[I 2023-04-20 15:23:04,508] Trial 80 finished with value: 25.335689045936395 and parameters: {'learning_rate': 0.00016168792433855333, 'batch_size': 8, 'num_epochs': 20, 'conv1_channels': 165, 'conv2_channels': 70, 'conv3_channels': 156, 'hidden_channels': 99, 'hidden_layers': 4}. Best is trial 63 with value: 26.925795053003533.
[I 2023-04-20 15:23:15,229] Trial 81 pruned.
[I 2023-04-20 15:23:20,560] Trial 82 pruned.
[I 2023-04-20 15:23:25,924] Trial 83 pruned.
[I 2023-04-20 15:23:31,405] Trial 84 pruned.
[I 2023-04-20 15:23:36,637] Trial 85 pruned.
[I 2023-04-20 15:23:45,675] Trial 86 pruned.
[I 2023-04-20 15:23:50,892] Trial 87 pruned.
[I 2023-04-20 15:24:53,435] Trial 88 pruned.
[I 2023-04-20 15:25:02,223] Trial 89 pruned.
[I 2023-04-20 15:25:07,399] Trial 90 pruned.
[I 2023-04-20 15:25:22,448] Trial 91 pruned.
[I 2023-04-20 15:25:52,722] Trial 92 pruned.
[I 2023-04-20 15:26:08,142] Trial 93 pruned.
[I 2023-04-20 15:26:40,182] Trial 94 pruned.
[I 2023-04-20 15:26:48,394] Trial 95 pruned.
[I 2023-04-20 15:26:56,543] Trial 96 pruned.
[I 2023-04-20 15:27:02,496] Trial 97 pruned.
[I 2023-04-20 15:27:11,121] Trial 98 pruned.
[I 2023-04-20 15:27:26,819] Trial 99 pruned.
Best trial:
  Value: 26.925795053003533
  Params:
    learning_rate: 9.143381850322516e-05
    batch_size: 8
    num_epochs: 37
    conv1_channels: 187
    conv2_channels: 176
    conv3_channels: 66
    hidden_channels: 114
    hidden_layers: 4