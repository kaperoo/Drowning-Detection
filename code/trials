[I 2023-03-28 21:10:41,102] Trial 0 finished with value: 0.2728102189781022 and parameters: {'learning_rate': 0.048649875674239486, 'batch_size': 120, 'num_epochs': 22, 'conv1_channels': 78, 'conv2_channels': 219, 'conv3_channels': 139}. Best is trial 0 with value: 0.2728102189781022.
[I 2023-03-28 21:17:05,863] Trial 1 finished with value: 0.9342051905920519 and parameters: {'learning_rate': 0.00029656601580377117, 'batch_size': 90, 'num_epochs': 46, 'conv1_channels': 150, 'conv2_channels': 103, 'conv3_channels': 71}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 21:19:40,119] Trial 2 finished with value: 0.7114253852392538 and parameters: {'learning_rate': 0.002248495400090092, 'batch_size': 90, 'num_epochs': 16, 'conv1_channels': 138, 'conv2_channels': 137, 'conv3_channels': 81}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 21:29:25,382] Trial 3 finished with value: 0.6318937550689375 and parameters: {'learning_rate': 0.00628680244764916, 'batch_size': 120, 'num_epochs': 41, 'conv1_channels': 226, 'conv2_channels': 204, 'conv3_channels': 188}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 21:33:59,567] Trial 4 finished with value: 0.8916261151662611 and parameters: {'learning_rate': 8.875141651414329e-05, 'batch_size': 30, 'num_epochs': 18, 'conv1_channels': 60, 'conv2_channels': 246, 'conv3_channels': 144}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 21:34:13,937] Trial 5 pruned. 
[I 2023-03-28 21:34:23,610] Trial 6 pruned. 
[I 2023-03-28 21:34:48,862] Trial 7 pruned. 
[I 2023-03-28 21:34:58,938] Trial 8 pruned. 
[I 2023-03-28 21:37:27,920] Trial 9 finished with value: 0.8647100567721006 and parameters: {'learning_rate': 0.0010626537377883786, 'batch_size': 120, 'num_epochs': 13, 'conv1_channels': 245, 'conv2_channels': 184, 'conv3_channels': 125}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 21:41:10,426] Trial 10 finished with value: 0.8911699107866992 and parameters: {'learning_rate': 0.00021346953412991747, 'batch_size': 90, 'num_epochs': 34, 'conv1_channels': 146, 'conv2_channels': 53, 'conv3_channels': 52}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 21:48:10,158] Trial 11 finished with value: 0.9186435523114356 and parameters: {'learning_rate': 0.00012456715512134786, 'batch_size': 30, 'num_epochs': 26, 'conv1_channels': 58, 'conv2_channels': 87, 'conv3_channels': 180}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 21:48:25,746] Trial 12 pruned. 
[I 2023-03-28 21:58:01,716] Trial 13 finished with value: 0.9119018653690186 and parameters: {'learning_rate': 0.0003228020427908081, 'batch_size': 30, 'num_epochs': 32, 'conv1_channels': 182, 'conv2_channels': 100, 'conv3_channels': 172}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 22:08:16,071] Trial 14 finished with value: 0.9266524736415247 and parameters: {'learning_rate': 7.865855980565418e-05, 'batch_size': 30, 'num_epochs': 39, 'conv1_channels': 113, 'conv2_channels': 60, 'conv3_channels': 240}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 22:08:26,096] Trial 15 pruned. 
[I 2023-03-28 22:08:43,627] Trial 16 pruned. 
[I 2023-03-28 22:12:47,931] Trial 17 pruned. 
[I 2023-03-28 22:12:56,561] Trial 18 pruned. 
[I 2023-03-28 22:22:39,926] Trial 19 finished with value: 0.9181366585563666 and parameters: {'learning_rate': 0.00017288767241612624, 'batch_size': 30, 'num_epochs': 37, 'conv1_channels': 201, 'conv2_channels': 164, 'conv3_channels': 77}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 22:22:52,391] Trial 20 pruned. 
[I 2023-03-28 22:30:01,707] Trial 21 finished with value: 0.9229521492295215 and parameters: {'learning_rate': 9.889589030169052e-05, 'batch_size': 30, 'num_epochs': 29, 'conv1_channels': 51, 'conv2_channels': 100, 'conv3_channels': 254}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 22:30:18,724] Trial 22 pruned. 
[I 2023-03-28 22:38:49,922] Trial 23 finished with value: 0.9135746147607462 and parameters: {'learning_rate': 0.0004179562860947316, 'batch_size': 30, 'num_epochs': 32, 'conv1_channels': 51, 'conv2_channels': 134, 'conv3_channels': 232}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 22:39:02,044] Trial 24 pruned. 
[I 2023-03-28 22:39:11,051] Trial 25 pruned. 
[I 2023-03-28 22:49:15,453] Trial 26 finished with value: 0.9196066504460665 and parameters: {'learning_rate': 0.00022473351258143676, 'batch_size': 30, 'num_epochs': 39, 'conv1_channels': 100, 'conv2_channels': 108, 'conv3_channels': 211}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 22:49:23,697] Trial 27 pruned. 
[I 2023-03-28 22:49:37,107] Trial 28 pruned. 
[I 2023-03-28 22:49:41,717] Trial 29 pruned. 
[I 2023-03-28 22:50:08,052] Trial 30 pruned. 
[I 2023-03-28 22:51:08,522] Trial 31 pruned. 
[I 2023-03-28 23:00:21,138] Trial 32 finished with value: 0.9239152473641524 and parameters: {'learning_rate': 9.209976324078404e-05, 'batch_size': 30, 'num_epochs': 35, 'conv1_channels': 107, 'conv2_channels': 111, 'conv3_channels': 217}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 23:11:36,072] Trial 33 finished with value: 0.9316200324412003 and parameters: {'learning_rate': 8.670949128168852e-05, 'batch_size': 30, 'num_epochs': 35, 'conv1_channels': 138, 'conv2_channels': 133, 'conv3_channels': 244}. Best is trial 1 with value: 0.9342051905920519.
[I 2023-03-28 23:11:55,110] Trial 34 pruned. 
[I 2023-03-28 23:12:16,247] Trial 35 pruned. 
[I 2023-03-28 23:12:29,618] Trial 36 pruned. 
[I 2023-03-28 23:25:05,761] Trial 37 finished with value: 0.9388179237631792 and parameters: {'learning_rate': 0.00016120141249167957, 'batch_size': 30, 'num_epochs': 38, 'conv1_channels': 130, 'conv2_channels': 129, 'conv3_channels': 244}. Best is trial 37 with value: 0.9388179237631792.
[I 2023-03-28 23:25:17,576] Trial 38 pruned. 
[I 2023-03-28 23:25:27,380] Trial 39 pruned. 
[I 2023-03-28 23:25:45,125] Trial 40 pruned. 
[I 2023-03-28 23:26:02,480] Trial 41 pruned. 
[I 2023-03-28 23:39:08,176] Trial 42 finished with value: 0.9347120843471208 and parameters: {'learning_rate': 0.0003000095173873876, 'batch_size': 30, 'num_epochs': 37, 'conv1_channels': 149, 'conv2_channels': 146, 'conv3_channels': 241}. Best is trial 37 with value: 0.9388179237631792.
[I 2023-03-28 23:53:33,934] Trial 43 finished with value: 0.9438868613138686 and parameters: {'learning_rate': 0.00034888185786523555, 'batch_size': 30, 'num_epochs': 41, 'conv1_channels': 150, 'conv2_channels': 147, 'conv3_channels': 244}. Best is trial 43 with value: 0.9438868613138686.
[I 2023-03-28 23:53:54,481] Trial 44 pruned. 
[I 2023-03-28 23:54:13,125] Trial 45 pruned. 
[I 2023-03-28 23:54:23,393] Trial 46 pruned. 
[I 2023-03-28 23:54:37,485] Trial 47 pruned. 
[I 2023-03-28 23:54:57,321] Trial 48 pruned. 
[I 2023-03-28 23:58:27,531] Trial 49 pruned. 
[I 2023-03-28 23:58:42,260] Trial 50 pruned. 
[I 2023-03-29 00:11:33,609] Trial 51 finished with value: 0.9387165450121655 and parameters: {'learning_rate': 0.00019423626647083317, 'batch_size': 30, 'num_epochs': 38, 'conv1_channels': 144, 'conv2_channels': 152, 'conv3_channels': 243}. Best is trial 43 with value: 0.9438868613138686.
[I 2023-03-29 00:24:55,427] Trial 52 finished with value: 0.935624493106245 and parameters: {'learning_rate': 0.00019129399846213937, 'batch_size': 30, 'num_epochs': 38, 'conv1_channels': 164, 'conv2_channels': 152, 'conv3_channels': 246}. Best is trial 43 with value: 0.9438868613138686.
[I 2023-03-29 00:38:17,179] Trial 53 finished with value: 0.9316707218167072 and parameters: {'learning_rate': 0.0002037576085086374, 'batch_size': 30, 'num_epochs': 38, 'conv1_channels': 163, 'conv2_channels': 157, 'conv3_channels': 226}. Best is trial 43 with value: 0.9438868613138686.
[I 2023-03-29 00:53:00,807] Trial 54 finished with value: 0.9189983779399837 and parameters: {'learning_rate': 0.0002999044584491118, 'batch_size': 30, 'num_epochs': 43, 'conv1_channels': 150, 'conv2_channels': 151, 'conv3_channels': 245}. Best is trial 43 with value: 0.9438868613138686.
[I 2023-03-29 00:53:25,129] Trial 55 pruned. 
[I 2023-03-29 00:53:39,103] Trial 56 pruned. 
[I 2023-03-29 00:54:02,041] Trial 57 pruned. 
[I 2023-03-29 00:54:18,577] Trial 58 pruned. 
[I 2023-03-29 00:54:37,506] Trial 59 pruned. 
[I 2023-03-29 00:54:53,960] Trial 60 pruned. 
[I 2023-03-29 01:07:50,468] Trial 61 finished with value: 0.938006893755069 and parameters: {'learning_rate': 0.00021266083754495978, 'batch_size': 30, 'num_epochs': 37, 'conv1_channels': 161, 'conv2_channels': 159, 'conv3_channels': 228}. Best is trial 43 with value: 0.9438868613138686.
[I 2023-03-29 01:08:13,198] Trial 62 pruned. 
[I 2023-03-29 01:21:20,003] Trial 63 finished with value: 0.9264497161394971 and parameters: {'learning_rate': 0.00014222326852084656, 'batch_size': 30, 'num_epochs': 38, 'conv1_channels': 149, 'conv2_channels': 157, 'conv3_channels': 238}. Best is trial 43 with value: 0.9438868613138686.
[I 2023-03-29 01:21:34,013] Trial 64 pruned. 
[I 2023-03-29 01:35:13,516] Trial 65 finished with value: 0.9419606650446066 and parameters: {'learning_rate': 0.00020489728405272083, 'batch_size': 30, 'num_epochs': 40, 'conv1_channels': 177, 'conv2_channels': 143, 'conv3_channels': 229}. Best is trial 43 with value: 0.9438868613138686.
[I 2023-03-29 01:49:51,823] Trial 66 finished with value: 0.9335462287104623 and parameters: {'learning_rate': 0.00019433670996693426, 'batch_size': 30, 'num_epochs': 40, 'conv1_channels': 198, 'conv2_channels': 178, 'conv3_channels': 228}. Best is trial 43 with value: 0.9438868613138686.
[I 2023-03-29 01:50:50,969] Trial 67 pruned. 
[I 2023-03-29 01:51:09,424] Trial 68 pruned. 
[I 2023-03-29 02:05:53,944] Trial 69 finished with value: 0.9143349553933495 and parameters: {'learning_rate': 0.0002043196304197005, 'batch_size': 30, 'num_epochs': 42, 'conv1_channels': 181, 'conv2_channels': 151, 'conv3_channels': 232}. Best is trial 43 with value: 0.9438868613138686.
[I 2023-03-29 02:06:19,946] Trial 70 pruned. 
[I 2023-03-29 02:06:30,807] Trial 71 pruned. 
[I 2023-03-29 02:06:46,972] Trial 72 pruned. 
[I 2023-03-29 02:07:00,067] Trial 73 pruned. 
[I 2023-03-29 02:23:04,992] Trial 74 finished with value: 0.9494626926196269 and parameters: {'learning_rate': 0.00024149705692512547, 'batch_size': 30, 'num_epochs': 43, 'conv1_channels': 163, 'conv2_channels': 162, 'conv3_channels': 235}. Best is trial 74 with value: 0.9494626926196269.
[I 2023-03-29 02:39:46,777] Trial 75 finished with value: 0.930352798053528 and parameters: {'learning_rate': 0.00023847760085411797, 'batch_size': 30, 'num_epochs': 43, 'conv1_channels': 191, 'conv2_channels': 161, 'conv3_channels': 237}. Best is trial 74 with value: 0.9494626926196269.
[I 2023-03-29 02:40:05,271] Trial 76 pruned. 
[I 2023-03-29 02:41:06,884] Trial 77 pruned. 
[I 2023-03-29 02:56:04,899] Trial 78 finished with value: 0.9431265206812652 and parameters: {'learning_rate': 0.00016263380594924986, 'batch_size': 30, 'num_epochs': 38, 'conv1_channels': 166, 'conv2_channels': 173, 'conv3_channels': 251}. Best is trial 74 with value: 0.9494626926196269.
[I 2023-03-29 03:11:38,817] Trial 79 finished with value: 0.9394261962692619 and parameters: {'learning_rate': 0.00016195649390642598, 'batch_size': 30, 'num_epochs': 40, 'conv1_channels': 212, 'conv2_channels': 193, 'conv3_channels': 250}. Best is trial 74 with value: 0.9494626926196269.
[I 2023-03-29 03:27:51,786] Trial 80 finished with value: 0.9224959448499594 and parameters: {'learning_rate': 0.00015474802411758322, 'batch_size': 30, 'num_epochs': 40, 'conv1_channels': 179, 'conv2_channels': 205, 'conv3_channels': 234}. Best is trial 74 with value: 0.9494626926196269.
[I 2023-03-29 03:28:39,559] Trial 81 pruned. 
[I 2023-03-29 03:47:07,198] Trial 82 finished with value: 0.936993106244931 and parameters: {'learning_rate': 0.00011121959072775121, 'batch_size': 30, 'num_epochs': 42, 'conv1_channels': 221, 'conv2_channels': 199, 'conv3_channels': 252}. Best is trial 74 with value: 0.9494626926196269.
[I 2023-03-29 03:47:34,175] Trial 83 pruned. 
[I 2023-03-29 03:47:59,757] Trial 84 pruned. 
[I 2023-03-29 03:48:25,605] Trial 85 pruned. 
[I 2023-03-29 04:06:51,738] Trial 86 finished with value: 0.9421634225466342 and parameters: {'learning_rate': 0.0001490110834796803, 'batch_size': 30, 'num_epochs': 46, 'conv1_channels': 220, 'conv2_channels': 214, 'conv3_channels': 229}. Best is trial 74 with value: 0.9494626926196269.
[I 2023-03-29 04:07:08,505] Trial 87 pruned. 
[I 2023-03-29 04:25:35,026] Trial 88 finished with value: 0.9442416869424168 and parameters: {'learning_rate': 0.00015183030369658528, 'batch_size': 30, 'num_epochs': 48, 'conv1_channels': 217, 'conv2_channels': 212, 'conv3_channels': 207}. Best is trial 74 with value: 0.9494626926196269.
[I 2023-03-29 04:46:52,250] Trial 89 finished with value: 0.9395782643957826 and parameters: {'learning_rate': 0.0001497932329042247, 'batch_size': 30, 'num_epochs': 49, 'conv1_channels': 233, 'conv2_channels': 206, 'conv3_channels': 213}. Best is trial 74 with value: 0.9494626926196269.
[I 2023-03-29 04:47:39,267] Trial 90 pruned. 
[I 2023-03-29 04:50:58,034] Trial 91 pruned. 
[I 2023-03-29 04:51:21,740] Trial 92 pruned. 
[I 2023-03-29 04:51:43,911] Trial 93 pruned. 
[I 2023-03-29 04:52:07,487] Trial 94 pruned. 
[I 2023-03-29 04:52:33,916] Trial 95 pruned. 
[I 2023-03-29 05:10:31,075] Trial 96 pruned. 
[I 2023-03-29 05:10:58,436] Trial 97 pruned. 
[I 2023-03-29 05:14:31,356] Trial 98 pruned. 
[I 2023-03-29 05:14:56,792] Trial 99 pruned. 
Best trial:
  Value: 0.9494626926196269
  Params: 
    learning_rate: 0.00024149705692512547
    batch_size: 30
    num_epochs: 43
    conv1_channels: 163
    conv2_channels: 162
    conv3_channels: 235
